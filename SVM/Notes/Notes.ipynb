{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ff909d-6747-4563-9ac0-719258b2183c",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) – Complete Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce45b6-b6c5-48db-932f-e8c48a2237d5",
   "metadata": {},
   "source": [
    "### 1. What is SVM?\n",
    "\n",
    "Support Vector Machine (SVM) is a supervised learning algorithm used for:\n",
    "- Classification\n",
    "- Regression (SVR)\n",
    "\n",
    "> SVM works by finding an optimal hyperplane that maximizes the margin between different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ac1fc8-92bb-486f-9a7b-5ff91f2f3c4b",
   "metadata": {},
   "source": [
    "### 2. Key Idea Behind SVM\n",
    "\n",
    "- Find the best decision boundary\n",
    "- Boundary should be as far as possible from nearest data points\n",
    "- Nearest points are called Support Vectors\n",
    "\n",
    "> Only support vectors influence the decision boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af92a0-9c58-49fe-b035-67072af50116",
   "metadata": {},
   "source": [
    "### 3. What is a Hyperplane?\n",
    "- 1D → Point\n",
    "- 2D → Line\n",
    "- 3D → Plane\n",
    "- nD → Hyperplane\n",
    "\n",
    "`Equation: wx + b=0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0c80bb-3f87-4b11-9fc0-fd8d819e55b1",
   "metadata": {},
   "source": [
    "### 4. Margin in SVM\n",
    "- Margin = Distance between hyperplane and closest data points\n",
    "- SVM aims to maximize margin\n",
    "\n",
    "**Types of Margin:**\n",
    "- Hard Margin SVM\n",
    "-Soft Margin SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312859b3-f358-4097-afcd-59a578b8c9a8",
   "metadata": {},
   "source": [
    "### 5. Hard Margin vs Soft Margin\n",
    "- **Misclassification**\n",
    "    - Hard Margin: Not allowed\n",
    "    - Soft Margin: Allowed\n",
    "- **Outliers**\n",
    "    - Hard Margin: Not handled\n",
    "    - Soft Margin: Handled\n",
    "- **Data Type**\n",
    "    - Hard Margin: Perfectly separable data\n",
    "    - Soft Margin: Real-world data\n",
    "- **Use Case**\n",
    "    - Hard Margin: Theoretical scenarios\n",
    "    - Soft Margin: Practical applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85983fb-5e42-490e-9508-03ee94b786de",
   "metadata": {},
   "source": [
    "### 6. Support Vectors\n",
    "- Data points closest to the hyperplane\n",
    "- Determine position of the decision boundary\n",
    "- Removing other points does not affect the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa25ac0-b30c-4fcc-822f-af0fa8f735d5",
   "metadata": {},
   "source": [
    "### 7. Kernel Trick (Very Important)\n",
    "- Used when data is not linearly separable\n",
    "- Transforms data into higher dimension\n",
    "- Makes linear separation possible\n",
    "- Computation done efficiently using kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763de86b-dd61-498f-88ba-17f81b736e45",
   "metadata": {},
   "source": [
    "### 8. Common Kernels\n",
    "- **Linear Kernel**\n",
    "    - Formula: (x · x′)\n",
    "    - Use Case: Linearly separable data\n",
    "- **Polynomial Kernel**\n",
    "    - Formula: (x · x′ + c)ᵈ\n",
    "    - Use Case: Curved decision boundaries\n",
    "- **RBF (Gaussian) Kernel**\n",
    "    - Formula: e^(−γ‖x − x′‖²)\n",
    "    - Use Case: Most commonly used kernel\n",
    "- **Sigmoid Kernel**\n",
    "    - Formula: tanh(x · x′)\n",
    "    - Use Case: Neural-network–like behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad039b-8ca5-4678-b8e6-dcc0e131702d",
   "metadata": {},
   "source": [
    "### 9. Multiclass SVM\n",
    "- SVM is naturally binary\n",
    "- Multiclass handled using:\n",
    "  - One-vs-Rest (OvR)\n",
    "  - One-vs-One (OvO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4d3918-958f-4a52-a1b2-da1da594f9b6",
   "metadata": {},
   "source": [
    "### 10. Evaluation Metrics\n",
    "Same as logistic regression:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-Score\n",
    "- ROC-AUC (for binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebecb165-910d-47a4-ab6d-b65958cff41a",
   "metadata": {},
   "source": [
    "### 11. Advantages of SVM\n",
    "- Works well in high-dimensional spaces\n",
    "- Effective with small datasets\n",
    "- Robust to overfitting (with proper C & γ)\n",
    "- Strong theoretical foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818a67cb-845a-496f-b3f2-bf62554686cc",
   "metadata": {},
   "source": [
    "### 12. Disadvantages of SVM\n",
    "- Computationally expensive for large datasets\n",
    "- Hard to tune hyperparameters\n",
    "- Less interpretable\n",
    "- Slow training with complex kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e360418-58ac-4744-ae55-b65045840175",
   "metadata": {},
   "source": [
    "### 13. Important Hyperparameters\n",
    "- **C**\n",
    "    - Meaning: Regularization strength\n",
    "- **kernel**\n",
    "    - Meaning: Type of kernel used\n",
    "- **gamma**\n",
    "    - Meaning: Influence of individual data points\n",
    "- **degree**\n",
    "    - Meaning: Degree of the polynomial kernel\n",
    "- **epsilon**\n",
    "    - Meaning: Margin of tolerance for SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a23123-5ef0-42bb-8051-06d98ec31985",
   "metadata": {},
   "source": [
    "### 14. When to Use SVM?\n",
    "- High-dimensional data\n",
    "- Small to medium dataset\n",
    "- Non-linear boundaries\n",
    "- Text & image classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
