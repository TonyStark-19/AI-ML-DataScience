{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebdcb5b1-9884-403d-be14-674bd5f7f9c0",
   "metadata": {},
   "source": [
    "## Linear Algebra for AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a7f5f0-4efa-4459-8a75-4693801ee4a2",
   "metadata": {},
   "source": [
    "### 1. Introduction to Linear Algebra (Why it matters)\n",
    "Linear Algebra is the language of AI.\n",
    "- **Dataset** → Represented as a **matrix**\n",
    "  - Rows = data samples\n",
    "  - Columns = features\n",
    "\n",
    "- **Feature vector** → Represented as a **vector**\n",
    "  - Each feature is a dimension\n",
    "\n",
    "- **Model weights** → Represented as a **vector or matrix**\n",
    "  - Vector in linear models\n",
    "  - Matrix in neural networks\n",
    "\n",
    "- **Prediction** → Computed using **dot product**\n",
    "  - `y = w · x + b`\n",
    "\n",
    "- **Optimization** → Uses **eigenvalues and gradients**\n",
    "  - Eigenvalues → PCA, curvature understanding\n",
    "  - Gradients → weight updates (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f8957c-56a0-48a5-861f-9112c9ec8719",
   "metadata": {},
   "source": [
    "### 2. Straight Lines\n",
    "**Equation of a line**\n",
    "- Slope–intercept: `y = mx + c`\n",
    "- General form: `ax + by + c = 0`\n",
    "\n",
    "**Vector form (important for AI):**\n",
    "\n",
    "$\\vec{r} = \\vec{a} + t\\vec{b}$\n",
    "\n",
    "**Why AI cares:**\n",
    "- Decision boundaries (Logistic Regression, SVM)\n",
    "- Hyperplanes in higher dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e854591f-5038-4506-9bf8-abb0aa4654ab",
   "metadata": {},
   "source": [
    "### 3. Distance Between Two Points\n",
    "\n",
    "For points $A(x_1, y_1), B(x_2, y_2):$\n",
    "\n",
    "$d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$\n",
    "\n",
    "`Vector form:`\n",
    "\n",
    "$d = \\|\\vec{a} - \\vec{b}\\|$\n",
    "\n",
    "**AI usage:**\n",
    "- KNN\n",
    "- Clustering (K-Means)\n",
    "- Similarity measures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cb9d3f-8334-432e-b5d8-e0d59e208fed",
   "metadata": {},
   "source": [
    "### 4. Parallel & Perpendicular Lines\n",
    "\n",
    "**Slopes:**\n",
    "- **Parallel** $\\rightarrow m_1 = m_2$\n",
    "- **Perpendicular** $\\rightarrow m_1 m_2 = -1$\n",
    "\n",
    "**Vector form:**\n",
    "- Parallel → vectors are scalar multiples\n",
    "- Perpendicular → dot product = 0\n",
    "\n",
    "**AI usage:**\n",
    "- Orthogonality in feature spaces\n",
    "- Independence of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431f9538-e148-42b9-a832-64eb92cba63f",
   "metadata": {},
   "source": [
    "### 5. Distance Between Parallel Lines\n",
    "\n",
    "`For:`\n",
    "\n",
    "$ax + by + c_1 = 0, \\quad ax + by + c_2 = 0$\n",
    "\n",
    "$d = \\frac{|c_1 - c_2|}{\\sqrt{a^2 + b^2}}$\n",
    "\n",
    "**AI relevance:**\n",
    "- Margin in SVM\n",
    "- Understanding classification confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28337659-45a3-48c6-a6d1-d5b0f0b4de96",
   "metadata": {},
   "source": [
    "### 6. Vectors (MOST IMPORTANT)\n",
    "**What is a vector?**\n",
    "- Magnitude + direction\n",
    "- In AI → features / embeddings\n",
    "\n",
    "$\\vec{v} = [v_1, v_2, \\dots, v_n]$\n",
    "\n",
    "**Norm (length):**\n",
    "- L2 norm:\n",
    "\n",
    "$\\|\\vec{v}\\| = \\sqrt{\\sum v_i^2}$\n",
    "\n",
    "> Interview tip:\n",
    "“Feature vectors live in high-dimensional space.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f67f3-a98b-4a7e-a0fc-dc023a39a5f1",
   "metadata": {},
   "source": [
    "### 7. Vector Addition\n",
    "\n",
    "$\\vec{a} + \\vec{b} = [a_1 + b_1, a_2 + b_2, \\dots]$\n",
    "\n",
    "**AI meaning:**\n",
    "- Combining features\n",
    "- Word embeddings (king − man + woman)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2795f0d3-ec09-4ea3-a64f-8b837db4e0af",
   "metadata": {},
   "source": [
    "### 8. Scalar Multiplication\n",
    "\n",
    "$k\\vec{v} = [kv_1, kv_2, \\dots]$\n",
    "\n",
    "**AI usage:**\n",
    "- Learning rate scaling\n",
    "- Weight updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b1f2b-96db-434c-9cc8-1e1a0ceca043",
   "metadata": {},
   "source": [
    "### 9. Dot Product (EXTREMELY IMPORTANT)\n",
    "\n",
    "$\\vec{a} \\cdot \\vec{b} = \\sum a_i b_i$\n",
    "\n",
    "`Also`\n",
    "\n",
    "$\\vec{a} \\cdot \\vec{b} = \\|\\vec{a}\\| \\|\\vec{b}\\| \\cos \\theta$\n",
    "\n",
    "**AI interpretation:**\n",
    "- Similarity\n",
    "- Projection\n",
    "- Prediction (Linear Regression)\n",
    "\n",
    "> Interview gold line:\n",
    "“Dot product measures similarity between vectors.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0e6007-fe29-4c0d-b57d-9283a9e953cb",
   "metadata": {},
   "source": [
    "### 10. Cross Product (Less Important)\n",
    "Only for 3D vectors.\n",
    "\n",
    "$\\vec{a} \\times \\vec{b} = \\text{vector perpendicular to both}$\n",
    "\n",
    "**AI usage:**\n",
    "- Rare\n",
    "- Mostly graphics / physics\n",
    "\n",
    "> Know formula, not deep theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d3a861-d0b8-41f3-bf67-4222afd1d7d4",
   "metadata": {},
   "source": [
    "### 11. Matrices\n",
    "Matrix = collection of vectors\n",
    "\n",
    "$A \\in \\mathbb{R}^{m \\times n}$\n",
    "\n",
    "**AI meaning:**\n",
    "- Dataset → rows = samples, columns = features\n",
    "- Weight matrix in neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08d701-d4e8-4c6f-83df-cf9fa3f4f29c",
   "metadata": {},
   "source": [
    "### 12. Operations on Matrices\n",
    "`Matrix Addition`\n",
    "- Same shape.\n",
    "\n",
    "`Matrix Multiplication`\n",
    "\n",
    "$C = AB$\n",
    "\n",
    "**Rule:**\n",
    "- `(m × n) · (n × p) → (m × p)`\n",
    "\n",
    "**AI usage:**\n",
    "- Forward pass in neural networks\n",
    "- Linear transformations\n",
    "\n",
    "> Interview trap:\n",
    "Matrix multiplication is NOT commutative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97b27b-84cc-4bcb-9b31-b34153277d74",
   "metadata": {},
   "source": [
    "### 13. Determinants\n",
    "`For 2×2:`\n",
    "\n",
    "$\\begin{vmatrix} a & b \\\\ c & d \\end{vmatrix} = ad - bc$\n",
    "\n",
    "**Meaning:**\n",
    "- Area/volume scaling\n",
    "- Matrix invertibility\n",
    "\n",
    "If `det = 0` → no inverse\n",
    "\n",
    "**AI usage:**\n",
    "- Inverse existence\n",
    "- Numerical stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714a92e-66a1-458c-b652-b1e9be07106d",
   "metadata": {},
   "source": [
    "### 14. Eigen Values & Eigen Vectors\n",
    "\n",
    "$A\\vec{v} = \\lambda\\vec{v}$\n",
    "\n",
    "- Direction stays same\n",
    "- Only magnitude changes\n",
    "\n",
    "**AI applications:**\n",
    "- PCA\n",
    "- Dimensionality reduction\n",
    "- Data variance understanding\n",
    "\n",
    "> Interview explanation:\n",
    "“Eigenvectors represent principal directions of data.”"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
